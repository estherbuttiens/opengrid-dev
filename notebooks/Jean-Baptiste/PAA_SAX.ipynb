{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports\n",
    "\n",
    "    !! IMPORTANT !!\n",
    "    If you did NOT install opengrid with pip, \n",
    "    make sure the path to the opengrid folder is added to your PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "import pandas as pd\n",
    "import charts\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "from opengrid.library import houseprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Houseprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp = houseprint.Houseprint()\n",
    "# for testing:\n",
    "# hp = houseprint.Houseprint(spreadsheet='unit and integration test houseprint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The houseprint, sites, devices and sensors all have a get_data method. In order to get these working for the fluksosensors, the houseprint creates a tmpo session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup sites, devices, sensors based on key\n",
    "\n",
    "These methods return a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp.find_site(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp.find_device('FL03001441')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensor = hp.find_sensor('d5a747b86224834f745f4c9775d70241')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sensor.site)\n",
    "print(sensor.unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup sites, devices, sensors based on search criteria\n",
    "\n",
    "These methods return a list with objects satisfying the criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "hp.search_sites(inhabitants=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "hp.search_sensors(type='electricity', direction='Import')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING METHODS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electricity = hp.find_sensor('212ce724e124fbde0fb649396375d099')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head = pd.Timestamp('20151114')\n",
    "tail = pd.Timestamp('20151115')\n",
    "originalGraph = electricity.get_data(head=head, tail=tail, diff=True, resample='min', unit='kW')\n",
    "charts.plot(originalGraph, stock=True, show='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 999, 'display.max_columns', 3):\n",
    "    print originalGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeStart = pd.Timestamp('20151114')\n",
    "timeStop = pd.Timestamp('20151115')\n",
    "electricityData = originalGraph.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lijst met versch electriciteitsmetingen van 5 nov 2015 tem 6 nov 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier Moving average filter opzetten (Type van een low-pass filter om smoothing toe te passen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movingAverage = pd.rolling_mean(electricityData,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinate 2 dataframes. One being the original dataset, one smoothed with a movering average filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([electricityData,movingAverage], axis=1, keys =('A','B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Moving Average + Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "charts.plot(df,stock=True,show='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "derivative = electricityData.diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinate electricityData and the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chartPlot = pd.concat([electricityData, derivative], axis = 1, keys = ('A','B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative + Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "charts.plot(chartPlot, stock = True, show ='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### List Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 999, 'display.max_columns', 3):\n",
    "    print originalGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables:\n",
    "\n",
    "electricityData,\n",
    "movingAverage,\n",
    "derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementing SAX</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFrame1= pd.DataFrame({'col1':[2.02, 2.33, 2.99, 6.85, 9.20, 8.80, 7.50, 6.00, 5.85, 3.85, 4.85, 3.85, 2.22, 1.45, 1.34], \n",
    "                         'col2':[0.50, 1.29, 2.58, 3.83, 3.25, 4.25, 3.83, 5.63, 6.44, 6.25, 8.75, 8.83, 3.25, 0.75, 0.72]})\n",
    "charts.plot(dataFrame1, stock=True, show='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Implementing z-score</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column1 = pd.DataFrame([2.02, 2.33, 2.99, 6.85, 9.20, 8.80, 7.50, 6.00, 5.85, 3.85, 4.85, 3.85, 2.22, 1.45, 1.34])\n",
    "column2 = pd.DataFrame([0.50, 1.29, 2.58, 3.83, 3.25, 4.25, 3.83, 5.63, 6.44, 6.25, 8.75, 8.83, 3.25, 0.75, 0.72])\n",
    "saxExample = pd.concat([column1,column2], axis=1)\n",
    "saxExample.columns=['A','B']\n",
    "saxExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#meanCol1 = column1.mean()\n",
    "#stdCol2 = column1.std()\n",
    "#meanCol2 = column2.mean()\n",
    "#stdCol2 = column2.std()\n",
    "def znormalization(ts):\n",
    "    #Pakt mean, std van kolom.\n",
    "    meanCalc = ts.mean(axis = 0)\n",
    "    stdCalc = ts.std(axis = 0)\n",
    "    return (ts - meanCalc) / stdCalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zScores=znormalization(saxExample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#zScoreCol1 = (column1-meanCol1)/stdCol1\n",
    "#zScoreCol2 = (column2-meanCol2)/stdCol2\n",
    "#zScores = pd.concat([zScoreCol1,zScoreCol2],axis = 1)\n",
    "#zScores.columns=['Col1','Col2']\n",
    "#zScores\n",
    "charts.plot(zScores,stock=True,show='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zScores.plot(style=\"-+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Paa transformation of z normalized graphs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paa_transform(timeSeries, n_pieces):\n",
    "    splitted = np.array_split(timeSeries, n_pieces) ## along columns as we want\n",
    "    return np.asarray(map(lambda xs: xs.mean(axis = 0), splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split9 = paa_transform(zScores,9)\n",
    "paaTransfo = np.repeat(split9,2, axis = 0)\n",
    "for i in [0, 1]:\n",
    "    pl.figure()\n",
    "    pl.plot(zScores.iloc[:, i], '-+', label = \"ts%i\"%i)\n",
    "    pl.plot(paaTransfo[:, i], label = \"paa%i\"%i)\n",
    "    pl.legend(loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfzScores=pd.DataFrame(zScores) #z-normalization\n",
    "dfzScores.columns=('col1','col2')\n",
    "\n",
    "dfPaaTransfo=pd.DataFrame(paaTransfo) #paa\n",
    "dfPaaTransfo.columns=('col1','col2')\n",
    "\n",
    "concat = pd.concat([dfzScores,dfPaaTransfo])\n",
    "charts.plot(concat,stock=True,show='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sax_transform(ts, n_pieces, alphabet):\n",
    "    \"\"\"\n",
    "    ts: columns of which are time serieses represented by np.array\n",
    "    n_pieces: number of segments in paa transformation\n",
    "    alphabet: the letters to be translated to, e.g. \"abcd\", \"ab\"\n",
    "    return np.array of ts's sax transformation\n",
    "    Steps:\n",
    "    1. znormalize\n",
    "    2. paa\n",
    "    3. find norm distribution breakpoints by scipy.stats\n",
    "    4. convert paa transformation into strings\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    alphabet_sz = len(alphabet)\n",
    "    thrholds = norm.ppf(np.linspace(1./alphabet_sz, \n",
    "                                    1-1./alphabet_sz, \n",
    "                                    alphabet_sz-1))\n",
    "    def translate(ts_values):\n",
    "        return np.asarray([(alphabet[0] if ts_value < thrholds[0]\n",
    "                else (alphabet[-1] if ts_value > thrholds[-1]\n",
    "                      else alphabet[np.where(thrholds <= ts_value)[0][-1]+1]))\n",
    "                           for ts_value in ts_values])\n",
    "    paa_ts = paa_transform(znormalization(ts), n_pieces)\n",
    "    return np.apply_along_axis(translate, 0, paa_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>applying sax transformation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array1=sax_transform(saxExample, 9, \"abcdef\")\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sax=pd.DataFrame(array1)\n",
    "sax.columns=(\"col1\",\"col2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make array of values from the letters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeArray(array1):\n",
    "    arrayValues=[]    \n",
    "    for i in range(0, array1.size-1):\n",
    "        if(i<array1.size):\n",
    "             arrayValues.append(ord(array1.iloc[i])-97)\n",
    "    df=pd.DataFrame(arrayValues)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lettersToNumbers = pd.concat([makeArray(sax.col1),makeArray(sax.col2)],axis=1)\n",
    "lettersToNumbers.columns=['col1','col2']\n",
    "lettersToNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arrayLettersToNumbers=lettersToNumbers.col1.as_matrix()\n",
    "arrayLettersToNumbersRepeat=np.repeat(arrayLettersToNumbers,2)\n",
    "charts.plot(arrayLettersToNumbersRepeat, stock=True, show='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparing sax_alphabet_graph with paa values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saxAndPaa=pd.concat([dfPaaTransfo.col1,znormalization(pd.DataFrame(arrayLettersToNumbersRepeat))],axis=1)\n",
    "saxAndPaa.columns=(\"col1\",\"col2\")\n",
    "charts.plot(saxAndPaa, stock=True,show='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparing orignal znormalized graph with sax</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newGraph=pd.concat([znormalization(pd.DataFrame(arrayLettersToNumbersRepeat)),znormalization(column1)],axis=1)\n",
    "newGraph.columns=['A','B']\n",
    "charts.plot(newGraph,stock=True,show='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Making dataframes of value differences between successive values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeDiffArray(array): #Excepts a letter array\n",
    "    arrayValues=[]    \n",
    "    for i in range(0, array.size-1):\n",
    "        if(i<array.size):\n",
    "             arrayValues.append(ord(array.iloc[i+1])-ord(array.iloc[i]))\n",
    "    df=pd.DataFrame(arrayValues)\n",
    "    return df          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "successive_df = pd.concat([makeDiffArray(sax.col1),makeDiffArray(sax.col2)],axis=1)\n",
    "successive_df.columns=['col1','col2']\n",
    "successive_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculating sax differences</h3>\n",
    "\n",
    "Differences are calculated between 2 arrays to see howmuch they are alike.\n",
    "We want values around 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def differenceNumbers(array): #Expects array of numbers @\n",
    "    arrayValues=[]\n",
    "    for i in range(0, array.index.size):\n",
    "        arrayValues.append(np.diff(array.iloc[i], axis=-1))\n",
    "    df=pd.DataFrame(arrayValues)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diffArrays(array1,array2):\n",
    "    array=[]\n",
    "    if array1.index.size==array2.index.size:\n",
    "        for i in range(0,array1.index.size):\n",
    "            array.append(array2.iloc[i]-array1.iloc[i])\n",
    "    df=pd.DataFrame(array)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arrayOfOnes=[]\n",
    "array2OfOnes=[]\n",
    "for i in range (0,87):\n",
    "    arrayOfOnes.append(1)\n",
    "    dfArrayOfOnes=pd.DataFrame(arrayOfOnes)\n",
    "for i in range (0,82):\n",
    "    array2OfOnes.append(2)\n",
    "    dfArray2OfOnes=pd.DataFrame(array2OfOnes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reCalculating difference between successive values of the array.\n",
    "This shows howmuch alike the arrays are with respect to the change of sucessive values.\n",
    "\n",
    "A lot of 0 and 1's means that the graphs will be alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "successive_difference_df = differenceNumbers(successive_df) #col2-col1\n",
    "successive_difference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def differenceLetters(array1, array2): #Expects array of Letters\n",
    "    array=[]\n",
    "    if array1.index.size == array2.index.size:\n",
    "        for i in range(0, array1.index.size-1):\n",
    "            array.append(ord(array2.iloc[i])-ord(array1.iloc[i]))\n",
    "    df=pd.DataFrame(array)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best is to first change array to number values, at them together, and then perform differencing operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First z-normalization\n",
    "Then paa\n",
    "\"\"\"\n",
    "\n",
    "zScoresOriginalGraph=znormalization(originalGraph)\n",
    "splitData = paa_transform(zScoresOriginalGraph,240)\n",
    "splitData_ext = np.repeat(splitData,4,axis = 0)\n",
    "pl.figure()\n",
    "pl.plot(zScoresOriginalGraph, '-+')\n",
    "pl.plot(splitData_ext)\n",
    "pl.legend(loc = \"upper left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparing original graph with paa values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splitDataDf=pd.DataFrame(splitData_ext)\n",
    "originalGraphDf=pd.DataFrame(originalGraph)\n",
    "splitDataDf=splitDataDf.iloc[:splitDataDf.size-20]\n",
    "splitDataDf.index=originalGraphDf.index\n",
    "graph = pd.concat([splitDataDf,zScoresOriginalGraph],axis=1).dropna()\n",
    "charts.plot(graph,stock=True,show='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saxTransformation=sax_transform(originalGraph, 240, \"abcdefghijklmn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Werkwijze:\n",
    "Dataframes gebruiken!\n",
    "-sax transfo\n",
    "-letters->nummers (makeArray())\n",
    "-np.repeat (plateau's)\n",
    "-plot(paa_transform+repeater,^)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Paa and Sax graph</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "letters=pd.DataFrame(saxTransformation)\n",
    "letters.columns=['col1']\n",
    "lettersToNumSax=makeArray(letters.col1) #Expects a pandaframe\n",
    "\n",
    "repeatedValues=np.repeat(lettersToNumSax.as_matrix(),4) #expects an array\n",
    "\n",
    "dfRepeatedValues=pd.DataFrame(repeatedValues)\n",
    "dfRepeatedValues=dfRepeatedValues.iloc[:dfRepeatedValues.size-16]\n",
    "splitDataDf.index=dfRepeatedValues.index\n",
    "\n",
    "concatinatePaaAndSax=pd.concat([znormalization(dfRepeatedValues),splitDataDf],axis=1)\n",
    "concatinatePaaAndSax.columns=['col1','col2']\n",
    "\n",
    "charts.plot(concatinatePaaAndSax,stock=True,show='inline')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>sax and original graph (znormalized)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfRepeatedValues.index=zScoresOriginalGraph.index\n",
    "saxVsOriginalGraph=pd.concat([(dfRepeatedValues), znormalization(originalGraph)],axis=1).dropna()\n",
    "charts.plot(saxVsOriginalGraph, stock=True, show='inline')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Methods for measuring the similarity of the arrays</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Hamming Distance (not so interesting for us)</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hammingDistance(s1, s2):\n",
    "    \"\"\"Return the Hamming distance between equal-length sequences\"\"\"\n",
    "    if len(s1) != len(s2):\n",
    "        raise ValueError(\"Undefined for sequences of unequal length\")\n",
    "    return sum(el1 != el2 for el1, el2 in zip(s1, s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h5>Euclidean Distance</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(s1,s2):\n",
    "    #Verwacht een numpy array\n",
    "    dist = np.linalg.norm(s1-s2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Cosine Similarity</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosineSimilarity(s1,s2):\n",
    "    similarity = 1 - spatial.distance.cosine(s1, s2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Mahalanobis Distance</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mahalanobisDistance(s1,s2):\n",
    "    similarity = 1 - distance.mahalanobis(s1,s2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Manhattan Distance</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def manhattanDistance(s1,s2):\n",
    "    difference=diffArrays(s1,s2)\n",
    "    absDifference=abs(difference)\n",
    "    sumOfValues=np.sum(absDifference)\n",
    "    maxValues=np.maximum(s1,s2)\n",
    "    maxValues=np.max(maxValues)\n",
    "    manhattan=sumOfValues/maxValues\n",
    "    return manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfRepeatedValues2=dfRepeatedValues\n",
    "with pd.option_context('display.max_rows', 999, 'display.max_columns', 3):\n",
    "    print dfRepeatedValues2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleData1=dfRepeatedValues.ix[pd.Timestamp('2015-11-14 15:22:00+00:00'):pd.Timestamp('2015-11-14 16:48:00+00:00')]\n",
    "sampleData2=dfRepeatedValues.ix[pd.Timestamp('2015-11-14 16:49:00+00:00'):pd.Timestamp('2015-11-14 18:18:00+00:00')]\n",
    "sampleData3=dfRepeatedValues.ix[pd.Timestamp('2015-11-14 18:19:00+00:00'):pd.Timestamp('2015-11-14 19:40:00+00:00')]\n",
    "sampleData1.columns=[\"sampleData1\"]\n",
    "sampleData2.columns=[\"sampleData2\"]\n",
    "sampleData3.columns=[\"sampleData3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array1=np.array((1,2,3,3,4,5,5,5,6,6,6,6,7,7,7,8,9,5,4,2,3))\n",
    "array2=np.array((1,5,3,5,3,2,2,5,5,6,6,6,7,7,7,8,9,6,5,2,3))\n",
    "\n",
    "euclideanDistance(array1,array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shorterSampleData2=sampleData2.iloc[:sampleData2.size-3]\n",
    "evenShorterSampleData2=sampleData2.iloc[:sampleData2.size-8]\n",
    "shorterSampleData1=sampleData1.iloc[:sampleData1.size-5]\n",
    "euclideanDistance(sampleData1.sampleData1,shorterSampleData2.sampleData2)\n",
    "\n",
    "nparraySampleData1=np.array((sampleData1))\n",
    "nparrayshorterSampleData1=np.array((shorterSampleData1))\n",
    "nparraySampleData2=np.array((shorterSampleData2))\n",
    "nparraySampleData3=np.array((sampleData3))\n",
    "nparrayevenShorterSampleData2=np.array((evenShorterSampleData2))\n",
    "print \"euclideanDistance 1 and 2:\", euclideanDistance(nparraySampleData1,nparraySampleData2)\n",
    "print \"euclideanDistance 1 and 3:\", euclideanDistance(nparrayshorterSampleData1,nparraySampleData3)\n",
    "print \"euclideanDistance 2 and 3:\", euclideanDistance(nparrayevenShorterSampleData2, nparraySampleData3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manhattan1=[1,2,3,3,5,5,46,6,6,7]\n",
    "manhattan2=[1,2,3,3,5,5,2,6,6,7]\n",
    "dfManhattan1=pd.DataFrame(manhattan1)\n",
    "dfManhattan2=pd.DataFrame(manhattan2)\n",
    "sampleData1.index=dfArrayOfOnes.index\n",
    "shorterSampleData2.index=dfArrayOfOnes.index\n",
    "arraySth=diffArrays(sampleData1.sampleData1,shorterSampleData2.sampleData2)\n",
    "arraySth\n",
    "absValue=abs(arraySth)\n",
    "sumsth=np.sum(absValue)\n",
    "maxValue=np.maximum(sampleData1.sampleData1,shorterSampleData2.sampleData2)\n",
    "maxValue=np.max(maxValue)\n",
    "test=sumsth/maxValue\n",
    "dfTest=pd.DataFrame(test)\n",
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manhattan1=[1,1,2,3,4,5,6,7,8,4,5,3]\n",
    "manhattan2=[1,1,4,6,4,2,3,7,9,4,5,3]\n",
    "dfArrayOfOnes.columns=['col1'] \n",
    "#Als je met vershillende kolomnamen zit weet het prog niet welke je bedoelt, dus moet je deze definieren.\n",
    "#dfManhattan1 en dfManhattan2 hebben zelfde kolomnamen. Daarom moet je niet nog eens defineren apart.\n",
    "print \"Manhattan with ones:\", manhattanDistance(dfManhattan1,dfManhattan2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"cosine similarity 1 and 2:\", cosineSimilarity(sampleData1,shorterSampleData2)\n",
    "print \"cosine similarity 1 and 3:\", cosineSimilarity(shorterSampleData1, sampleData3)\n",
    "print \"cosine similarity 2 and 3:\", cosineSimilarity(evenShorterSampleData2, sampleData3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"manhattan 1:\", manhattanDistance(sampleData1.sampleData1,dfArrayOfOnes.col1)\n",
    "print \"manhattan 2:\", manhattanDistance(sampleData1.sampleData1,shorterSampleData2.sampleData2)\n",
    "print \"manhattan 3:\", manhattanDistance(sampleData3.sampleData3, evenShorterSampleData2.sampleData2)\n",
    "\n",
    "print \"Hier zien we duidelijk een verschil mbt gelijkaardigheid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"manhattan 1:\", euclideanDistance(sampleData1.sampleData1,dfArrayOfOnes.col1)\n",
    "print \"manhattan 2:\", euclideanDistance(sampleData1.sampleData1,shorterSampleData2.sampleData2)\n",
    "print \"manhattan 3:\", euclideanDistance(nparrayevenShorterSampleData2, nparraySampleData3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=np.zeros(87)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#return np.asarray(ord(sax.col1.iloc[i+1])-ord(sax.col1.iloc[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}