{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "import pandas as pd\n",
    "import charts\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from opengrid.library import houseprint\n",
    "from scipy.spatial import distance\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp = houseprint.Houseprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = hp.find_device('FL03001441')\n",
    "device.get_sensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get Gas data\n",
    "head = pd.Timestamp('20151110')\n",
    "tail = pd.Timestamp('20151128')\n",
    "electr = hp.find_sensor('212ce724e124fbde0fb649396375d099')\n",
    "df_el = electr.get_data(head,tail,diff=True,resample='min',  unit='kW')\n",
    "df_el_dropna = df_el.dropna()\n",
    "df_el = pd.DataFrame(df_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if df_el.size <= 0:\n",
    "    print \"Dataframe is empty\"\n",
    "    \n",
    "charts.plot(df_el.rolling(window=6,center=False).median(), show=\"inline\", stock=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def znormalization(ts):\n",
    "    \"\"\"\n",
    "    ts - each column of ts is a time series (np.ndarray)\n",
    "    \"\"\"\n",
    "    mus = ts.mean(axis = 0)\n",
    "    stds = ts.std(axis = 0)\n",
    "    return (ts - mus) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paa_transform(ts, n_pieces):\n",
    "    \"\"\"\n",
    "    ts: the columns of which are time series represented by e.g. np.array\n",
    "    n_pieces: M equally sized piecies into which the original ts is splitted\n",
    "    \"\"\"\n",
    "    splitted = np.array_split(ts, n_pieces) ## along columns as we want\n",
    "    return np.asarray(map(lambda xs: xs.mean(axis = 0), splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sax_transform(ts, n_pieces, alphabet):\n",
    "    \"\"\"\n",
    "    ts: columns of which are time serieses represented by np.array\n",
    "    n_pieces: number of segments in paa transformation\n",
    "    alphabet: the letters to be translated to, e.g. \"abcd\", \"ab\"\n",
    "    return np.array of ts's sax transformation\n",
    "    Steps:\n",
    "    1. znormalize\n",
    "    2. ppa\n",
    "    3. find norm distribution breakpoints by scipy.stats\n",
    "    4. convert ppa transformation into strings\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    alphabet_sz = len(alphabet)\n",
    "    thrholds = norm.ppf(np.linspace(1./alphabet_sz, \n",
    "                                    1-1./alphabet_sz, \n",
    "                                    alphabet_sz-1))\n",
    "    def translate(ts_values):\n",
    "        return np.asarray([(alphabet[0] if ts_value < thrholds[0]\n",
    "                else (alphabet[-1] if ts_value > thrholds[-1]\n",
    "                      else alphabet[np.where(thrholds <= ts_value)[0][-1]+1]))\n",
    "                           for ts_value in ts_values])\n",
    "    paa_ts = paa_transform(znormalization(ts), n_pieces)\n",
    "    return np.apply_along_axis(translate, 0, paa_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeArray(array1):\n",
    "    arrayValues=[]    \n",
    "    for i in range(0, array1.size-1):\n",
    "        if(i<array1.size):\n",
    "             arrayValues.append(ord(array1.iloc[i])-97)\n",
    "    df=pd.DataFrame(arrayValues)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph_from(df):\n",
    "    list_with_graphs=[]\n",
    "    list_with_graphs=pd.DataFrame(list_with_graphs)\n",
    "    for i in range (0, df.index.size):\n",
    "        list_with_graphs=list_with_graphs.append(df_el.ix[pd.Timestamp(df['start'][i]):pd.Timestamp(df['stop'][i])])\n",
    "    return charts.plot(list_with_graphs, stock=True, show='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manhattanDistance2(s1,s2):\n",
    "    dist = distance.cityblock(s1,s2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_max_consumption(start, stop, parent, threshold=4):\n",
    "    head = pd.Timestamp(start)\n",
    "    tail = pd.Timestamp(stop)\n",
    "    temp = parent.ix[head:tail]\n",
    "    \n",
    "    if temp.values.max() - temp.values.min() < threshold:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_duplicate(blocks, start, stop):\n",
    "    \n",
    "    #blocks.reset_index(drop=True, inplace=True)\n",
    "    start = pd.Timestamp(start)\n",
    "    stop = pd.Timestamp(stop)\n",
    "    \n",
    "    \n",
    "    for i in range(blocks.index.size):\n",
    "        check_start = pd.Timestamp(blocks['start'].iloc[i])\n",
    "        check_stop = pd.Timestamp(blocks['stop'].iloc[i])\n",
    "    \n",
    "        if start == check_start or stop == check_stop or (start > check_start and stop < check_stop):\n",
    "            if (stop - start)/(check_stop - check_start) > 0.75:\n",
    "                return False, blocks\n",
    "            \n",
    "        if start < check_start and stop > check_stop:\n",
    "            if (check_stop - check_start)/(stop - start) > 0.75:\n",
    "                blocks = blocks.drop(blocks.index[i])\n",
    "                \n",
    "            \n",
    "    return True, blocks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_blocks(df_parent, row_parent, blocks, df_original, first_time = True):\n",
    "    min_lvl = 0\n",
    "    start = False\n",
    "    \n",
    "    block_start = 0\n",
    "    block_end = 0\n",
    "    index_low = -1\n",
    "    \n",
    "    nr_of_blocks_start = blocks.size\n",
    "    \n",
    "    nested = row_parent\n",
    "    \n",
    "    if first_time:\n",
    "        start = True\n",
    "        min_lvl = df_parent['repeatedValues'].min()\n",
    "        \n",
    "    #append last value again\n",
    "    post_index = df_parent.index[-1] + pd.Timedelta(minutes=1)\n",
    "\n",
    "    temp = pd.DataFrame(data=[df_parent.iloc[-1]], index=[post_index], columns=['repeatedValues'])\n",
    "    df_parent = df_parent.append(temp)\n",
    "\n",
    "    df_parent.sort_index(inplace=True)\n",
    "\n",
    "    for i in range(1, df_parent.size - 1):\n",
    "        if start == False and df_parent['repeatedValues'].iloc[i - 1] - df_parent['repeatedValues'].iloc[i] == 0:\n",
    "            min_lvl = df_parent['repeatedValues'].iloc[i]\n",
    "            start = True\n",
    "        \n",
    "        if start == True and df_parent['repeatedValues'].iloc[i] > min_lvl and df_parent['repeatedValues'].iloc[i - 1] == min_lvl:\n",
    "            block_start = df_parent.index[i - 1]\n",
    "            \n",
    "        if start == True and block_start != 0 and df_parent['repeatedValues'].iloc[i] <= min_lvl:\n",
    "            block_end = df_parent.index[i]\n",
    "            \n",
    "            #Match if the length is more than 10% less than the parent\n",
    "            temp = pd.DataFrame(data=[[str(block_start), str(block_end), nested]], columns=['start', 'stop', 'nested_in'])\n",
    "            \n",
    "            if float(df_parent.index.size - df_parent.ix[block_start : block_end].index.size) / float(df_parent.index.size) > 0.10:\n",
    "                # check if block is longer than 15 min\n",
    "                if(block_end - block_start > pd.Timedelta(minutes=15)):\n",
    "                    # check max consumption is greater than threshold\n",
    "                    if check_max_consumption(start=block_start, stop=block_end, parent=df_parent):\n",
    "                        # Check for duplicates\n",
    "                        check, blocks = check_duplicate(blocks, block_start, block_end)\n",
    "                        if check:\n",
    "                            #print [block_start, block_end]\n",
    "                            blocks = blocks.append(temp, ignore_index=True)\n",
    "            \n",
    "            df_parent2 = df_original.ix[block_start : block_end]\n",
    "            row_parent = blocks.index.size - 1\n",
    "            blocks = find_blocks(df_parent2, row_parent, blocks, df_original, False)\n",
    "            blocks =  blocks.drop_duplicates(subset=['start', 'stop'], keep= 'first')\n",
    "            block_start = 0\n",
    "            block_end = 0\n",
    "            \n",
    "        if start == True and block_start == 0 and df_parent['repeatedValues'].iloc[i] < min_lvl:\n",
    "            #Lvl dropped below min value so the min value was not assigned properly\n",
    "            # Store the timestamp where the value is the lowest for the first time.\n",
    "            if index_low == -1:\n",
    "                index_low = i\n",
    "                \n",
    "            if df_parent['repeatedValues'].iloc[index_low] > df_parent['repeatedValues'].iloc[i]:\n",
    "                index_low = i\n",
    "            \n",
    "            if df_parent['repeatedValues'].iloc[i+1] > df_parent['repeatedValues'].iloc[i]:\n",
    "                \n",
    "                #Match if the length is more than 10% less than the parent\n",
    "                temp = pd.DataFrame(data=[[str(df_parent.index[0]), str(df_parent.index[index_low]), nested]], columns=['start', 'stop', 'nested_in'])\n",
    "            \n",
    "                if float(df_parent.index.size - df_parent.ix[df_parent.index[0] : df_parent.index[index_low]].index.size) / float(df_parent.index.size) > 0.10:\n",
    "                    # check if block is longer than 15 min\n",
    "                    if(df_parent.index[index_low]-df_parent.index[0] > pd.Timedelta(minutes=15)):\n",
    "                        # check max consumption is greater than threshold\n",
    "                        if check_max_consumption(start=df_parent.index[0], stop=df_parent.index[index_low], parent=df_parent):\n",
    "                            # check for duplicates\n",
    "                            check, blocks = check_duplicate(blocks, df_parent.index[0], df_parent.index[index_low])\n",
    "                            if check:\n",
    "                                blocks = blocks.append(temp, ignore_index=True)\n",
    "                \n",
    "                min_lvl = df_parent['repeatedValues'].iloc[index_low]\n",
    "                \n",
    "    #blocks.reset_index(drop=True, inplace=True)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyValidationError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blockdetection(dataframe):\n",
    "    \n",
    "    if dataframe.size <= 0:\n",
    "        raise MyValidationError(\"Dataframe must have a size bigger than 0\")\n",
    "    \n",
    "        return None, None\n",
    "    \n",
    "    #Take the rolling mean to filter out peaks\n",
    "    df_rm = dataframe.rolling(window=6,center=False).median()\n",
    "    df_rm.index = df_rm.index - pd.Timedelta(minutes=3)\n",
    "    df_rm = df_rm.dropna()\n",
    "    \n",
    "    #saxtransform\n",
    "    saxTransmation = sax_transform(df_rm, df_rm.size/3, \"abcdefghijklmnop\")\n",
    "    \n",
    "    #Revert the letters to numbers\n",
    "    letters=pd.DataFrame(saxTransmation)\n",
    "    letters.columns=['col1']\n",
    "    lettersToNumSax=makeArray(letters.col1) #Expects a pandaframe\n",
    "\n",
    "    repeatedValues=np.repeat(lettersToNumSax.as_matrix(),3) #expects an array\n",
    "    #make sure the dataframes are of the same length to join the data and the index\n",
    "    shortage = df_rm.size - repeatedValues.size\n",
    "    if shortage > 0:\n",
    "        repeatedValues = np.append(repeatedValues, [repeatedValues[-1]]*shortage)\n",
    "\n",
    "    elif shortage < 0:\n",
    "        repeatedValues = repeatedValues[0:repeatedValues.size + shortage]\n",
    "    \n",
    "    shortage = df_rm.size - repeatedValues.size\n",
    "    \n",
    "    df_repeatedValues = pd.DataFrame(index=df_rm.index, data= repeatedValues, columns=['repeatedValues'])\n",
    "    \n",
    "    #pre- and append a zero to make sure the sample starts and ends with the same value\n",
    "    for i in range(0, 2):\n",
    "        pre_index = df_repeatedValues.index[0] - pd.Timedelta(minutes=1)\n",
    "        post_index = df_repeatedValues.index[-1] + pd.Timedelta(minutes=1)\n",
    "\n",
    "        temp = pd.DataFrame(data=[df_repeatedValues.min()], index=[pre_index], columns=['repeatedValues'])\n",
    "        df_repeatedValues = df_repeatedValues.append(temp)\n",
    "\n",
    "        temp = pd.DataFrame(data=[df_repeatedValues.min()], index=[post_index], columns=['repeatedValues'])\n",
    "        df_repeatedValues = df_repeatedValues.append(temp)\n",
    "\n",
    "        df_repeatedValues.sort_index(inplace=True)\n",
    "    \n",
    "    #Do the actual searching\n",
    "    blocks = pd.DataFrame(columns=['start', 'stop', 'nested_in'])\n",
    "    blocks = find_blocks(df_repeatedValues, -1, blocks, df_repeatedValues)\n",
    "    \n",
    "    #plot the dataframe with all the blocks\n",
    "    fig, ax = plt.subplots()\n",
    "    #ax.plot(df_repeatedValues.index, df_repeatedValues, color='grey')\n",
    "    ax.plot(df_rm.index, df_rm, color='grey')\n",
    "\n",
    "    colors = 100*['red', 'blue', 'orange', 'green', 'yellow']\n",
    "\n",
    "\n",
    "    for i in range(0, blocks.index.size):\n",
    "        ax.axvspan(blocks['start'].iloc[i], blocks['stop'].iloc[i], alpha=0.1, color=colors[3])\n",
    "        #ax.axvspan(str(pd.Timestamp(blocks['start'].iloc[i])), str(pd.Timestamp(blocks['stop'].iloc[i]) + pd.Timedelta(minutes=2)), alpha=0.1, color=colors[3])\n",
    "        #ax.axvspan(str(pd.Timestamp(blocks['start'].iloc[i])), str(pd.Timestamp(blocks['stop'].iloc[i])), alpha=0.1, color=colors[3])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #return the rolling mean equivalent and the blocks dataframe\n",
    "    return df_rm, blocks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sax_rm_shortage(dataframe):\n",
    "    \n",
    "    if dataframe.size <= 0:\n",
    "        raise MyValidationError(\"Dataframe must have a size bigger than 0\")\n",
    "    \n",
    "        return None, None\n",
    "    \n",
    "    #Take the rolling mean to filter out peaks\n",
    "    df_rm = dataframe.rolling(window=6,center=False).median()\n",
    "    df_rm.index = df_rm.index - pd.Timedelta(minutes=3)\n",
    "    df_rm = df_rm.dropna()\n",
    "    \n",
    "    #saxtransform\n",
    "    saxTransmation = sax_transform(df_rm, df_rm.size/3, \"abcdefghijklmnop\")\n",
    "    \n",
    "    #Revert the letters to numbers\n",
    "    letters=pd.DataFrame(saxTransmation)\n",
    "    letters.columns=['col1']\n",
    "    lettersToNumSax=makeArray(letters.col1) #Expects a pandaframe\n",
    "\n",
    "    repeatedValues=np.repeat(lettersToNumSax.as_matrix(),3) #expects an array\n",
    "    #make sure the dataframes are of the same length to join the data and the index\n",
    "    shortage = df_rm.size - repeatedValues.size\n",
    "    if shortage > 0:\n",
    "        repeatedValues = np.append(repeatedValues, [repeatedValues[-1]]*shortage)\n",
    "\n",
    "    elif shortage < 0:\n",
    "        repeatedValues = repeatedValues[0:repeatedValues.size + shortage]\n",
    "    \n",
    "    shortage = df_rm.size - repeatedValues.size\n",
    "    \n",
    "    df_repeatedValues = pd.DataFrame(index=df_rm.index, data= repeatedValues, columns=['repeatedValues'])\n",
    "    return df_repeatedValues, df_rm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blockdetection(df_repeatedValues, df_rm):\n",
    "#pre- and append a zero to make sure the sample starts and ends with the same value\n",
    "    for i in range(0, 2):\n",
    "        pre_index = df_repeatedValues.index[0] - pd.Timedelta(minutes=1)\n",
    "        post_index = df_repeatedValues.index[-1] + pd.Timedelta(minutes=1)\n",
    "\n",
    "        temp = pd.DataFrame(data=[df_repeatedValues.min()], index=[pre_index], columns=['repeatedValues'])\n",
    "        df_repeatedValues = df_repeatedValues.append(temp)\n",
    "\n",
    "        temp = pd.DataFrame(data=[df_repeatedValues.min()], index=[post_index], columns=['repeatedValues'])\n",
    "        df_repeatedValues = df_repeatedValues.append(temp)\n",
    "\n",
    "        df_repeatedValues.sort_index(inplace=True)\n",
    "    \n",
    "    #Do the actual searching\n",
    "    blocks = pd.DataFrame(columns=['start', 'stop', 'nested_in'])\n",
    "    blocks = find_blocks(df_repeatedValues, -1, blocks, df_repeatedValues)\n",
    "    \n",
    "    #plot the dataframe with all the blocks\n",
    "    fig, ax = plt.subplots()\n",
    "    #ax.plot(df_repeatedValues.index, df_repeatedValues, color='grey')\n",
    "    ax.plot(df_rm.index, df_rm, color='grey')\n",
    "\n",
    "    colors = 100*['red', 'blue', 'orange', 'green', 'yellow']\n",
    "\n",
    "\n",
    "    for i in range(0, blocks.index.size):\n",
    "        #ax.axvspan(blocks['start'].iloc[i], blocks['stop'].iloc[i], alpha=0.1, color=colors[3])\n",
    "        ax.axvspan(str(pd.Timestamp(blocks['start'].iloc[i])), str(pd.Timestamp(blocks['stop'].iloc[i]) + pd.Timedelta(minutes=2)), alpha=0.1, color=colors[3])\n",
    "        #ax.axvspan(str(pd.Timestamp(blocks['start'].iloc[i])), str(pd.Timestamp(blocks['stop'].iloc[i])), alpha=0.1, color=colors[3])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #return the rolling mean equivalent and the blocks dataframe\n",
    "    return df_rm, blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def looping_through_list(df_with_values, array_to_compare):\n",
    "    start=time.time()\n",
    "    #Create list where values on which the different methods will act will be saved temporarily\n",
    "    #This list will be cleared every time\n",
    "    values_list=[]\n",
    "    #Create list with results of the methods\n",
    "    result_list=[]\n",
    "    compare_to_array=np.array(array_to_compare)\n",
    "    i=0 #Loops through list arrayToCompare.size times\n",
    "    j=0 #Amount of values considered, and calculated.\n",
    "    array_with_values=np.array(df_with_values)\n",
    "    #start and stop timestamp\n",
    "    starting_time_stamp=df_with_values.index[0]\n",
    "    stop_time_stamp=df_with_values.index[array_to_compare.size-1]\n",
    "    \n",
    "    #Threshold\n",
    "    threshold_value=array_to_compare.size/10\n",
    "    #LOOPING THROUGH LIST\n",
    "    while i < array_to_compare.size+j: #i is dependent on j, i updates as j updates.\n",
    "        #Save x amount of values where x is the size of the array to compare.\n",
    "        values_list.append(([array_with_values[i][0]]))\n",
    "        i=i+1\n",
    "        if(i==(array_to_compare.size+j)) and (i<(df_with_values.size)):\n",
    "            #j = the minute at this moment. i = starting from the current minute, adding the size of the array to compare.\n",
    "            #Stops running when the limit of values to be considered is reached, being the size the original array.\n",
    "            if(j==0) or (manhattanDistance2(compare_to_array,values_list)!=result_list[len(result_list)-1][0]):\n",
    "                #Create list with unique values. Save them in \"resultList\". Euclidean score, startTimestamp, stopTimestamp\n",
    "                result_list.append([manhattanDistance2(compare_to_array,values_list), starting_time_stamp,stop_time_stamp]) \n",
    "            j=j+1\n",
    "            starting_time_stamp=df_with_values.index[j] #startingTimeStamp: current minute considered\n",
    "            stop_time_stamp=df_with_values.index[i] #stopTimeStamp: current minute considered + size of array to compare.\n",
    "            i=j\n",
    "            values_list=[]\n",
    "    print time.time()-start\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def local_minima_ts_correction(result_list):\n",
    "    start=time.time()\n",
    "    loop_index=0 #Loops throu\"gh the resultslist, as long as its size\n",
    "    current_saves=0 #Current amount of variables saved\n",
    "    some_list=[]\n",
    "    df_result=pd.DataFrame(some_list)\n",
    "    ts=(list_view[0][2]-list_view[0][1])/10\n",
    "    threshold_value=(ts / np.timedelta64(1, 'm')).astype(int)\n",
    "    #SAVING ONLY RELEVANT VALUES       \n",
    "    while loop_index < len(result_list):\n",
    "        if(loop_index==0):\n",
    "            [value,start_time_stamp,stop_time_stamp] = [result_list[loop_index][0], result_list[loop_index][1], result_list[loop_index][2]]\n",
    "            df_result=df_result.append(pd.DataFrame([[value, start_time_stamp,stop_time_stamp]], index=[current_saves], columns=['Manhattan','startTimeStamp','stopTimeStamp']))\n",
    "            current_saves=current_saves+1\n",
    "        if(result_list[loop_index-1][0] < result_list[loop_index-2][0]) and (result_list[loop_index-1][0] < result_list[loop_index][0]) and result_list[loop_index-1][0] < df_result.max()['Manhattan']:\n",
    "            #print \"Value\", resultList[loopIndex-1][0],\",Index:\",loopIndex-1,\"has a lower value than value left and right to it.(\",resultList[loopIndex-2][0],\",\",resultList[loopIndex][0],\") nIt will now replace\", dfResult['Euclidean'].max(),\"in the dataset.\"\n",
    "            [value,start_time_stamp,stop_time_stamp] = [result_list[loop_index-1][0], result_list[loop_index-1][1], result_list[loop_index-1][2]]\n",
    "            list_with_values=[]\n",
    "            i=0\n",
    "            max_value=0\n",
    "            #!!!Timestamps are important. If timestamp is within the range of another timestamp already present,\n",
    "            #they will overwrite eachother instead of adding a new unique value\n",
    "            while i < df_result.index.size:\n",
    "                if(start_time_stamp >= df_result['startTimeStamp'][i]) and (start_time_stamp <= df_result['stopTimeStamp'][i]-pd.Timedelta(minutes=threshold_value)):\n",
    "                    #INSIDE BOUNDARIES\n",
    "                    if(df_result.loc[i][0] > max_value) and (df_result.loc[i][0]!=0): #Store the maximum value, of the range between start and stoptimestamp.\n",
    "                        max_value=df_result.loc[i][0]\n",
    "                        ts=df_result.loc[i][1]\n",
    "                    elif(df_result.loc[i][0]==0): #PERFECT MATCH\n",
    "                        max_value=1 #Not 0 because otherwise we assume it is outside of the boundaries\n",
    "                i=i+1\n",
    "            if(max_value==0): \n",
    "                #OUTSIDE BOUNDARIES\n",
    "                    df_result=df_result.append(pd.DataFrame([[value, start_time_stamp,stop_time_stamp]], index=[current_saves], columns=['Manhattan','startTimeStamp','stopTimeStamp']))\n",
    "                    current_saves=current_saves+1\n",
    "                #INSIDE BOUNDARIES - \n",
    "            elif(value < max_value): #Check if the current value is smaller than the Maximum value encountered. Replace if it is.\n",
    "                    df_result.loc[df_result['Manhattan']== max_value] = [value, start_time_stamp, stop_time_stamp]\n",
    "        loop_index=loop_index+1\n",
    "    df_result=df_result.sort_values(['Manhattan'])\n",
    "    print time.time()-start\n",
    "    return df_result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_threshold_value(df_result, nr_of_best_values, factor):\n",
    "    list_of_best_values=[]\n",
    "    i = 0\n",
    "    for i in range(0, nr_of_best_values):\n",
    "        list_of_best_values.append(df_result.iloc[i])\n",
    "    list_of_best_values=pd.DataFrame(list_of_best_values)\n",
    "    mean=list_of_best_values.mean()\n",
    "    threshold=mean*factor\n",
    "    print threshold\n",
    "    return df_result.loc[df_result['Manhattan']<=threshold[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    frame, df_rm=sax_rm_shortage(df_el)\n",
    "    originalrm, blocks = blockdetection(frame, df_rm)\n",
    "    \n",
    "except MyValidationError as exception:\n",
    "    # handle exception here and get error message\n",
    "    print exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Indexing dataframe </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(blocks.index.size):\n",
    "    head = pd.Timestamp(blocks['start'].iloc[i]) #- pd.Timedelta('2min')\n",
    "    tail = pd.Timestamp(blocks['stop'].iloc[i]) + pd.Timedelta('2min')\n",
    "    #df_el = electr.get_data(head,tail,diff=True,resample='min',  unit='kW').dropna()\n",
    "    temp = df_rm.ix[head:tail]\n",
    "    \n",
    "    plt.plot(temp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> indexing and creating list of blocks with '-1' index <h/4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_blocks=[]\n",
    "list_blocks=pd.DataFrame(list_blocks)\n",
    "\n",
    "for i in range (0, blocks.index.size):\n",
    "    if(blocks['nested_in'][i] == -1.0):\n",
    "        list_blocks=list_blocks.append((blocks.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dfblocks = [1]\n",
    "# dfblocks=pd.DataFrame(dfblocks,index=[0])\n",
    "# for i in range (1,len(list_blocks)):\n",
    "#     dfblocks=dfblocks.append(pd.DataFrame([i], index=[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_big_blocks(list_of_blocks):\n",
    "    list_blocks=[]\n",
    "    for i in range(0, list_of_blocks.index.size):\n",
    "        if(blocks['nested_in'][i] == -1.0):\n",
    "            list_blocks.append(list_of_blocks.iloc[i])\n",
    "    list_blocks=pd.DataFrame(list_blocks)\n",
    "    list_blocks.reset_index(drop=True, inplace=True)\n",
    "    return list_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> visualisation of original frames found by block detection </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create_graph_from(list_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_el.ix[pd.Timestamp(list_blocks['start'][0]):pd.Timestamp(list_blocks['stop'][0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Loop through indexes and calculate score </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> looping begins </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def looping_through_list(df_with_values, array_to_compare):\n",
    "    start=time.time()\n",
    "    #Create list where values on which the different methods will act will be saved temporarily\n",
    "    #This list will be cleared every time\n",
    "    values_list=[]\n",
    "    #Create list with results of the methods\n",
    "    result_list=[]\n",
    "    compare_to_array=np.array(array_to_compare)\n",
    "    i=0 #Loops through list arrayToCompare.size times\n",
    "    j=0 #Amount of values considered, and calculated.\n",
    "    array_with_values=np.array(df_with_values)\n",
    "    #start and stop timestamp\n",
    "    starting_time_stamp=df_with_values.index[0]\n",
    "    stop_time_stamp=df_with_values.index[array_to_compare.size-1]\n",
    "    #Threshold\n",
    "    threshold_value=array_to_compare.size/10\n",
    "    #LOOPING THROUGH LIST\n",
    "    if(array_to_compare.index.size != df_with_values.index.size):\n",
    "        while i < array_to_compare.size+j: #i is dependent on j, i updates as j updates.\n",
    "            #Save x amount of values where x is the size of the array to compare.\n",
    "            values_list.append(([array_with_values[i][0]]))\n",
    "            i=i+1\n",
    "            if(i==(array_to_compare.size+j)) and (i<(df_with_values.size)):\n",
    "                #print df_with_values.size\n",
    "                #j = the minute at this moment. i = starting from the current minute, adding the size of the array to compare.\n",
    "                #Stops running when the limit of values to be considered is reached, being the size the original array.\n",
    "                if(j==0) or (manhattanDistance2(compare_to_array,values_list)!=result_list[len(result_list)-1][0]):\n",
    "                    #Create list with unique values. Save them in \"resultList\". Euclidean score, startTimestamp, stopTimestamp\n",
    "                    result_list.append([manhattanDistance2(compare_to_array,values_list), starting_time_stamp,stop_time_stamp])     \n",
    "                j=j+1\n",
    "                starting_time_stamp=df_with_values.index[j] #startingTimeStamp: current minute considered\n",
    "                stop_time_stamp=df_with_values.index[array_to_compare.size+j-1] #stopTimeStamp: current minute considered + size of array to compare.\n",
    "                #Storing last stop_time_stamp\n",
    "                if(array_to_compare.size+j-1 == df_with_values.size-1):\n",
    "                    result_list.append([manhattanDistance2(compare_to_array,values_list), starting_time_stamp,stop_time_stamp])     \n",
    "                i=j\n",
    "                values_list=[]\n",
    "    else:\n",
    "        print \"in here\"\n",
    "        result_list.append([manhattanDistance2(compare_to_array,df_with_values), starting_time_stamp,stop_time_stamp])     \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_blocks['Type']=1\n",
    "for i in range(0, list_blocks.index.size):\n",
    "    list_blocks['Type'][i] = list_blocks.index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks['Type']=1\n",
    "k=0\n",
    "for i in range(0, blocks.index.size):\n",
    "    if(blocks['nested_in'][i]==-1.0):\n",
    "        j = 0\n",
    "        blocks['Type'][i] = blocks.index[i]\n",
    "        k=i\n",
    "    else:\n",
    "#         print blocks.index[k],\"\",j\n",
    "        blocks['Type'][i] = blocks.index[k],\".. \",j\n",
    "        j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Get Gas data\n",
    "# head = pd.Timestamp('20151110')\n",
    "# tail = pd.Timestamp('20151118')\n",
    "# electr = hp.find_sensor('212ce724e124fbde0fb649396375d099')\n",
    "# df_el = electr.get_data(head,tail,diff=True,resample='min',  unit='kW')\n",
    "# df_el_dropna = df_el.dropna()\n",
    "# df_el = pd.DataFrame(df_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def looping_through_list_original(df_list_blocks):\n",
    "#     start_time = time.time()\n",
    "#     time_now = time.time()\n",
    "#     #Create list of costs\n",
    "#     cost_list = []\n",
    "#     #Creating variable 'j'. This will make sure we don't check the same frames twice.\n",
    "#     j=0\n",
    "#     #Other variable\n",
    "#     k=0\n",
    "#     for i in range(0, df_list_blocks.index.size):\n",
    "#         start = df_list_blocks.iloc[i][0]\n",
    "#         stop = df_list_blocks.iloc[i][1]\n",
    "#         #This will create a dataframe with all the values between the start and stop timestamp.\n",
    "#         #This is used for comparing these values using a similarity algorithm with the others\n",
    "#         df_original = df_el.ix[pd.Timestamp(start):pd.Timestamp(stop)]\n",
    "#         type_original = df_list_blocks.iloc[i][3]\n",
    "#         print type_original\n",
    "#         if(k==1):\n",
    "#             print \"After type: \", j, \"we will raise 'j' so that the next type \", j+1, \"won't be compared again with type \", j\n",
    "#             j=j+1\n",
    "#         for i in range(j, df_list_blocks.index.size):\n",
    "#             df_new = df_el.ix[pd.Timestamp(df_list_blocks.iloc[i][0]):pd.Timestamp(df_list_blocks.iloc[i][1])]\n",
    "#             if(df_new.index.size > df_original.index.size):\n",
    "# #                 print \"looping\"\n",
    "#                 result = looping_through_list(df_new, df_original)\n",
    "#                 if(min(result)[0] not in [row[0][0] for row in cost_list]):\n",
    "#                     cost_list.append((min(result), ('Original: Type', type_original, 'against type', df_list_blocks.iloc[i][3])))\n",
    "#             elif(df_new.index.size < df_original.index.size):\n",
    "# #                 print \"looping\"\n",
    "#                 result = looping_through_list(df_original, df_new)\n",
    "#                 if(min(result)[0] not in [row[0][0] for row in cost_list]):\n",
    "#                     cost_list.append((min(result), ('Substitute: Type', df_list_blocks.iloc[i][3], 'against original type', type_original)))\n",
    "#             k=1\n",
    "#     print  \"Time to complete: \", time.time() - start_time\n",
    "#     return cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list_view = looping_through_list_original(list_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(list_view):\n",
    "    df_list_view=[]\n",
    "    df_list_view=pd.DataFrame(df_list_view)\n",
    "\n",
    "    df_substitutes=[]\n",
    "    df_substitutes=pd.DataFrame(df_substitutes)\n",
    "    for i in range(0, len(list_view)):\n",
    "        if(list_view[i][1][0] == 'Substitute: Type'):\n",
    "            df_substitutes = df_substitutes.append(pd.DataFrame([[list_view[i][0][0],list_view[i][0][1],list_view[i][0][2], list_view[i][1]]], columns=['Manhattan', 'start', 'stop', 'Frame'], index=[i]))\n",
    "        else:       \n",
    "            df_list_view = df_list_view.append(pd.DataFrame([[list_view[i][0][0],list_view[i][0][1],list_view[i][0][2], list_view[i][1]]], columns=['Manhattan', 'start', 'stop', 'Frame'], index=[i]))\n",
    "    return df_substitutes, df_list_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = df_el.ix[pd.Timestamp(blocks.iloc[0][0]):pd.Timestamp(blocks.iloc[0][1])]\n",
    "test_2 = df_el.ix[pd.Timestamp(blocks.iloc[1][0]):pd.Timestamp(blocks.iloc[1][1])]\n",
    "i=1\n",
    "if(i==1) and not(test.equals(test_2)):\n",
    "    print \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_big_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def looping_through_list_original(df_list_blocks):\n",
    "    start_time = time.time()\n",
    "    time_now = time.time()\n",
    "    #Create list of costs\n",
    "    cost_list = []\n",
    "    #Crating variable 'j'. This will make sure we don't check the same frames twice.\n",
    "    j=1\n",
    "    #Other variable\n",
    "    k=0\n",
    "    for i in range(0, df_list_blocks.index.size):\n",
    "        start = df_list_blocks.iloc[i][0]\n",
    "        stop = df_list_blocks.iloc[i][1]\n",
    "        #This will create a dataframe with all the values between the start and stop timestamp.\n",
    "        #This is used for comparing these values using a similarity algorithm with the others\n",
    "        df_original = df_el.ix[pd.Timestamp(start):pd.Timestamp(stop)]\n",
    "        #Type of the block\n",
    "        type_original = df_list_blocks.iloc[i][3]\n",
    "        #Original or nested in\n",
    "        original_or_nested = df_list_blocks.iloc[i][2]\n",
    "        #get the big blocks\n",
    "        df_list_big_blocks = find_big_blocks(df_list_blocks)\n",
    "        nr_loops=0\n",
    "        print type_original\n",
    "        if(k==1) and (original_or_nested == -1.0):\n",
    "            j=j+1\n",
    "        for i in range(j, df_list_big_blocks.index.size):\n",
    "            df_new = df_el.ix[pd.Timestamp(df_list_big_blocks.iloc[i][0]):pd.Timestamp(df_list_big_blocks.iloc[i][1])]\n",
    "            if(df_new.index.size >= df_original.index.size) and not(df_new.equals(df_original)) :\n",
    "                nr_loops=nr_loops+1\n",
    "                print \"looping: \", nr_loops\n",
    "                result = looping_through_list(df_new, df_original)\n",
    "                if(min(result)[0] not in [row[0][0] for row in cost_list]):\n",
    "                    cost_list.append((min(result), ('Original: Type', type_original, 'against type', df_list_big_blocks.iloc[i][3])))\n",
    "            elif(df_new.index.size < df_original.index.size):\n",
    "                nr_loops=nr_loops+1                \n",
    "                print \"looping: \", nr_loops\n",
    "                result = looping_through_list(df_original, df_new)\n",
    "                if(min(result)[0] not in [row[0][0] for row in cost_list]):\n",
    "                    cost_list.append((min(result), ('Substitute: Type', df_list_big_blocks.iloc[i][3], 'against original type', type_original)))\n",
    "            k=1\n",
    "    print  \"Time to complete: \", time.time() - start_time\n",
    "    return cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_view = looping_through_list_original(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_substitutes, df_list_view = create_dataframe(list_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 6):\n",
    "    print df_list_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list_sorted = df_list_view.sort_values('Manhattan')\n",
    "df_substitutes_sorted = df_substitutes.sort_values('Frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_list_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2 = df_el.ix[pd.Timestamp(df_list_sorted['start'][2]):pd.Timestamp(df_list_sorted['stop'][2])]\n",
    "df_1 = df_el.ix[pd.Timestamp(blocks['start'][2]):pd.Timestamp(blocks['stop'][2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_list_sorted['start'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manhattanDistance2(df_1, df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_concat=pd.concat([df_2,df_1])\n",
    "charts.plot(df_1, stock=True, show='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}