{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "import pandas as pd\n",
    "import charts\n",
    "import time\n",
    "import math\n",
    "\n",
    "from opengrid.library import houseprint\n",
    "\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp = houseprint.Houseprint()\n",
    "hp.sync_tmpos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = hp.find_device('FL03001441')\n",
    "device.get_sensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get Electricity data\n",
    "head = pd.Timestamp('2015-12-15 01:00:00')\n",
    "tail = pd.Timestamp('2015-12-16 01:00:00')\n",
    "electr = hp.find_sensor('ce8ab098fc7479dcb3699f307c8e88a7')\n",
    "df_el = electr.get_data(head,tail,diff=True, unit='W')\n",
    "df_el = df_el.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get Gas data\n",
    "head = pd.Timestamp('2015-12-15 01:00:00')\n",
    "tail = pd.Timestamp('2015-12-16 01:00:00')\n",
    "electr = hp.find_sensor('212ce724e124fbde0fb649396375d099')\n",
    "df_el = electr.get_data(head,tail,diff=True, unit='W')\n",
    "df_el = df_el.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if df_el.size <= 0:\n",
    "    print \"Dataframe is empty\"\n",
    "    \n",
    "charts.plot(df_el, show=\"inline\", stock=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def znormalization(ts):\n",
    "    \"\"\"\n",
    "    ts - each column of ts is a time series (np.ndarray)\n",
    "    \"\"\"\n",
    "    mus = ts.mean(axis = 0)\n",
    "    stds = ts.std(axis = 0)\n",
    "    return (ts - mus) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paa_transform(ts, n_pieces):\n",
    "    \"\"\"\n",
    "    ts: the columns of which are time series represented by e.g. np.array\n",
    "    n_pieces: M equally sized piecies into which the original ts is splitted\n",
    "    \"\"\"\n",
    "    splitted = np.array_split(ts, n_pieces) ## along columns as we want\n",
    "    return np.asarray(map(lambda xs: xs.mean(axis = 0), splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sax_transform(ts, n_pieces, alphabet):\n",
    "    \"\"\"\n",
    "    ts: columns of which are time serieses represented by np.array\n",
    "    n_pieces: number of segments in paa transformation\n",
    "    alphabet: the letters to be translated to, e.g. \"abcd\", \"ab\"\n",
    "    return np.array of ts's sax transformation\n",
    "    Steps:\n",
    "    1. znormalize\n",
    "    2. ppa\n",
    "    3. find norm distribution breakpoints by scipy.stats\n",
    "    4. convert ppa transformation into strings\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    alphabet_sz = len(alphabet)\n",
    "    thrholds = norm.ppf(np.linspace(1./alphabet_sz, \n",
    "                                    1-1./alphabet_sz, \n",
    "                                    alphabet_sz-1))\n",
    "    def translate(ts_values):\n",
    "        return np.asarray([(alphabet[0] if ts_value < thrholds[0]\n",
    "                else (alphabet[-1] if ts_value > thrholds[-1]\n",
    "                      else alphabet[np.where(thrholds <= ts_value)[0][-1]+1]))\n",
    "                           for ts_value in ts_values])\n",
    "    paa_ts = paa_transform(znormalization(ts), n_pieces)\n",
    "    return np.apply_along_axis(translate, 0, paa_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeArray(array1):\n",
    "    arrayValues=[]    \n",
    "    for i in range(0, array1.size-1):\n",
    "        if(i<array1.size):\n",
    "             arrayValues.append(ord(array1.iloc[i])-97)\n",
    "    df=pd.DataFrame(arrayValues)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_blocks(df_parent, row_parent, blocks, df_original, first_time = True):\n",
    "    min_lvl = 0\n",
    "    start = False\n",
    "    \n",
    "    block_start = 0\n",
    "    block_end = 0\n",
    "    \n",
    "    nr_of_blocks_start = blocks.size\n",
    "    \n",
    "    nested = row_parent\n",
    "    \n",
    "    if first_time:\n",
    "        start = True\n",
    "        min_lvl = df_parent['repeatedValues'].min()\n",
    "        \n",
    "    #append last value again\n",
    "    post_index = df_parent.index[-1] + pd.Timedelta(minutes=1)\n",
    "\n",
    "    temp = pd.DataFrame(data=[df_parent.iloc[-1]], index=[post_index], columns=['repeatedValues'])\n",
    "    df_parent = df_parent.append(temp)\n",
    "\n",
    "    df_parent.sort_index(inplace=True)\n",
    "\n",
    "    for i in range(1, df_parent.size - 1):\n",
    "        if start == False and df_parent['repeatedValues'].iloc[i - 1] - df_parent['repeatedValues'].iloc[i] == 0:\n",
    "            min_lvl = df_parent['repeatedValues'].iloc[i]\n",
    "            start = True\n",
    "        \n",
    "        if start == True and df_parent['repeatedValues'].iloc[i] > min_lvl and df_parent['repeatedValues'].iloc[i - 1] == min_lvl:\n",
    "            block_start = df_parent.index[i - 1]\n",
    "            \n",
    "        if start == True and block_start != 0 and df_parent['repeatedValues'].iloc[i] <= min_lvl:\n",
    "            block_end = df_parent.index[i]\n",
    "            \n",
    "            #Match if the length is more than 10% less than the parent\n",
    "            temp = pd.DataFrame(data=[[str(block_start), str(block_end), nested]], columns=['start', 'stop', 'nested_in'])\n",
    "            \n",
    "            if float(df_parent.index.size - df_parent.ix[block_start : block_end].index.size) / float(df_parent.index.size) > 0.10:\n",
    "                blocks = blocks.append(temp)\n",
    "            \n",
    "            df_parent2 = df_original.ix[block_start : block_end]\n",
    "            row_parent = blocks.index.size - 1\n",
    "            blocks = find_blocks(df_parent2, row_parent, blocks, df_original, False)\n",
    "            \n",
    "            block_start = 0\n",
    "            block_end = 0\n",
    "            \n",
    "        if start == True and block_start == 0 and df_parent['repeatedValues'].iloc[i] < min_lvl:\n",
    "            #Lvl dropped below min value so the min value was not assigned properly\n",
    "            if df_parent['repeatedValues'].iloc[i+1] >= df_parent['repeatedValues'].iloc[i]:\n",
    "                \n",
    "                #Match if the length is more than 10% less than the parent\n",
    "                temp = pd.DataFrame(data=[[str(df_parent.index[0]), str(df_parent.index[i]), nested]], columns=['start', 'stop', 'nested_in'])\n",
    "                \n",
    "                if float(df_parent.index.size - df_parent.ix[df_parent.index[0] : df_parent.index[i]].index.size) / float(df_parent.index.size) > 0.10:\n",
    "                    blocks = blocks.append(temp)\n",
    "                \n",
    "                min_lvl = df_parent['repeatedValues'].iloc[i]\n",
    "                \n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyValidationError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blockdetection(dataframe):\n",
    "    \n",
    "    if dataframe.size <= 0:\n",
    "        raise MyValidationError(\"Dataframe must have a size bigger than 0\")\n",
    "    \n",
    "        return None, None\n",
    "    \n",
    "    #Take the rolling mean to filter out peaks\n",
    "    df_rm = dataframe.rolling(window=6,center=False).median()\n",
    "    df_rm.index = df_rm.index - pd.Timedelta(minutes=3)\n",
    "    df_rm = df_rm.dropna()\n",
    "    \n",
    "    #Z normalize\n",
    "    zScoresOriginalGraph=znormalization(df_rm)\n",
    "    \n",
    "    #Paa transform\n",
    "    splitData = paa_transform(zScoresOriginalGraph, df_rm.size/3) #size of df devided by 3 (if 3 in next line remains)\n",
    "    splitData_ext = np.repeat(splitData,3,axis = 0)\n",
    "    \n",
    "    #make sure the dataframes are of the same length to join the data and the index\n",
    "    shortage = df_rm.size - splitData_ext.size\n",
    "    if shortage > 0:\n",
    "        splitData_ext = np.append(splitData_ext, [splitData_ext[-1]]*shortage)\n",
    "\n",
    "    elif shortage < 0:\n",
    "        splitData_ext = splitData_ext[:abs(shortage)-1]\n",
    "\n",
    "    shortage = df_rm.size - splitData_ext.size\n",
    "    \n",
    "    df_paa = pd.DataFrame(index=df_rm.index, data=splitData_ext)\n",
    "    \n",
    "    #saxtransform\n",
    "    saxTransmation = sax_transform(df_paa, df_rm.size/3, \"abcdefghijklmnop\")\n",
    "    \n",
    "    #Revert the letters to numbers\n",
    "    letters=pd.DataFrame(saxTransmation)\n",
    "    letters.columns=['col1']\n",
    "    lettersToNumSax=makeArray(letters.col1) #Expects a pandaframe\n",
    "\n",
    "    repeatedValues=np.repeat(lettersToNumSax.as_matrix(),3) #expects an array\n",
    "    \n",
    "    #make sure the dataframes are of the same length to join the data and the index\n",
    "    shortage = df_rm.size - repeatedValues.size\n",
    "    if shortage > 0:\n",
    "        repeatedValues = np.append(repeatedValues, [repeatedValues[-1]]*shortage)\n",
    "\n",
    "    elif shortage < 0:\n",
    "        repeatedValues = repeatedValues[0:repeatedValues.size + shortage]\n",
    "    \n",
    "    shortage = df_rm.size - repeatedValues.size\n",
    "    \n",
    "    df_repeatedValues = pd.DataFrame(index=df_rm.index, data= repeatedValues, columns=['repeatedValues'])\n",
    "    \n",
    "    #pre- and append a zero to make sure the sample starts and ends with the same value\n",
    "    for i in range(0, 2):\n",
    "        pre_index = df_repeatedValues.index[0] - pd.Timedelta(minutes=1)\n",
    "        post_index = df_repeatedValues.index[-1] + pd.Timedelta(minutes=1)\n",
    "\n",
    "        temp = pd.DataFrame(data=[df_repeatedValues.min()], index=[pre_index], columns=['repeatedValues'])\n",
    "        df_repeatedValues = df_repeatedValues.append(temp)\n",
    "\n",
    "        temp = pd.DataFrame(data=[df_repeatedValues.min()], index=[post_index], columns=['repeatedValues'])\n",
    "        df_repeatedValues = df_repeatedValues.append(temp)\n",
    "\n",
    "        df_repeatedValues.sort_index(inplace=True)\n",
    "    \n",
    "    #Do the actual searching\n",
    "    blocks = pd.DataFrame(columns=['start', 'stop', 'nested_in'])\n",
    "    blocks = find_blocks(df_repeatedValues, -1, blocks, df_repeatedValues)\n",
    "    \n",
    "    #plot the dataframe with all the blocks\n",
    "    fig, ax = plt.subplots()\n",
    "    #ax.plot(df_repeatedValues.index, df_repeatedValues, color='grey')\n",
    "    ax.plot(df_rm.index, df_rm, color='grey')\n",
    "\n",
    "    colors = 100*['red', 'blue', 'orange', 'green', 'yellow']\n",
    "\n",
    "\n",
    "    for i in range(0, blocks.index.size):\n",
    "        #ax.axvspan(blocks['start'].iloc[i], blocks['stop'].iloc[i], alpha=0.1, color=colors[3])\n",
    "        #ax.axvspan(str(pd.Timestamp(blocks['start'].iloc[i]) + pd.Timedelta(minutes=3)), str(pd.Timestamp(blocks['stop'].iloc[i]) + pd.Timedelta(minutes=3)), alpha=0.1, color=colors[3])\n",
    "        ax.axvspan(str(pd.Timestamp(blocks['start'].iloc[i])), str(pd.Timestamp(blocks['stop'].iloc[i])), alpha=0.1, color=colors[3])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #return the rolling mean equivalent and the blocks dataframe\n",
    "    return df_rm, blocks.drop_duplicates(subset=['start', 'stop'], keep= 'first')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    original_rm, blocks = blockdetection(df_el)\n",
    "except MyValidationError as exception:\n",
    "    # handle exception here and get error message\n",
    "    print exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensors = hp.get_sensors(sensortype='gas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(sensors)):\n",
    "    key = str(sensors[i]).splitlines()[2][9:]\n",
    "    electr = hp.find_sensor(str(key))\n",
    "    df_el = electr.get_data(head,tail,diff=True, unit='W')\n",
    "    df_el = df_el.dropna()\n",
    "    \n",
    "    try:\n",
    "        original_rm, blocks = blockdetection(df_el)\n",
    "    except MyValidationError as exception:\n",
    "        # handle exception here and get error message\n",
    "        print exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}